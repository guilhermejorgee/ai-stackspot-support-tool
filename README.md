# Integra√ß√£o PydanticAI + LiteLLM + Stackspot

Este guia mostra como conectar um agente PydanticAI ao seu proxy LiteLLM local que utiliza o Stackspot como provider.

## üìã Pr√©-requisitos

1. **Instalar depend√™ncias**:
```bash
pip install -r requirements.txt
```

2. **Verificar configura√ß√£o do proxy**:
   - Arquivo `config.yaml` configurado
   - Custom handler `custom_handler.py` implementado
   - Suporte a tools funcionando

## üöÄ Como Usar

### 1. Iniciar o Proxy LiteLLM

```bash

# Op√ß√£o 2: Comando direto
litellm --config config.yaml --port 4000
```

O proxy ficar√° dispon√≠vel em `http://localhost:4000`

### 2. Configurar PydanticAI

```python
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel

# Configurar modelo para usar proxy local
model = OpenAIModel(
    model_name='stackspot-chat',  # Nome definido no config.yaml
    base_url='http://localhost:4000/v1',  # URL do proxy
    api_key='fake-key'  # N√£o √© necess√°ria chave real
)

# Criar agente com tools
agent = Agent(
    model=model,
    tools=[sua_funcao_tool1, sua_funcao_tool2],
    system_prompt="Voc√™ √© um assistente √∫til..."
)
```

### 3. Executar Agente

```python
# Executar consulta
result = await agent.run("Sua pergunta aqui")
print(result.data)
```

## üîß Configura√ß√µes Avan√ßadas

### Timeouts e Retries

```python
model = OpenAIModel(
    model_name='stackspot-chat',
    base_url='http://localhost:4000/v1',
    api_key='fake-key'
)
```

### Vari√°veis de Ambiente

Crie um arquivo `.env`:

```bash
LITELLM_BASE_URL=http://localhost:4000/v1
LITELLM_MODEL_NAME=stackspot-chat
LITELLM_API_KEY=fake-key
```

## üõ†Ô∏è Troubleshooting

### Proxy n√£o responde
- Verifique se o proxy est√° rodando: `curl http://localhost:4000/health`
- Confirme a porta: pode estar sendo usada por outro processo
- Verifique logs do LiteLLM para erros de autentica√ß√£o

### PydanticAI n√£o encontra tools
- Certifique-se de que o custom handler est√° detectando tool calls corretamente
- Teste diretamente o proxy: `curl -X POST http://localhost:4000/v1/chat/completions`
- Verifique se as tools est√£o sendo passadas no formato correto

### Erros de autentica√ß√£o do Stackspot
- Confirme as credenciais no `custom_handler.py`
- Teste autentica√ß√£o: `python debug_test.py`
- Verifique se o JWT n√£o expirou

### Performance lenta
- O Stackspot pode ter limita√ß√µes de rate limiting
- Considere implementar cache para respostas
- Use connection pooling no httpx/requests

## üìä Monitoramento

### Logs do Proxy
```bash
# Iniciar com logs detalhados
litellm --config config.yaml --port 4000 --verbose
```

### M√©tricas do PydanticAI
```python
# Acessar hist√≥rico de mensagens
result = await agent.run("pergunta")
print(f"Mensagens trocadas: {len(result.all_messages())}")
print(f"Custo estimado: {result.cost()}")
```

## üîó Endpoints Dispon√≠veis

Quando o proxy estiver rodando:

- **Chat**: `POST http://localhost:4000/v1/chat/completions`
- **Models**: `GET http://localhost:4000/v1/models`  
- **Health**: `GET http://localhost:4000/health`
- **Metrics**: `GET http://localhost:4000/metrics` (se habilitado)

## üìù Exemplo Completo

Veja `pydantic_agent_example.py` para um exemplo completo com:
- Configura√ß√£o do modelo
- Defini√ß√£o de tools personalizadas  
- Testes de diferentes cen√°rios
- Conversas multi-turn
- Tratamento de erros

## üéØ Pr√≥ximos Passos

1. **Produ√ß√£o**: Configure HTTPS, autentica√ß√£o e rate limiting
2. **Monitoramento**: Adicione m√©tricas e alertas
3. **Scaling**: Use load balancer para m√∫ltiplas inst√¢ncias
4. **Cache**: Implemente cache para respostas frequentes